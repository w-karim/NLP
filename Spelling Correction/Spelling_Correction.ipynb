{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, TweetTokenizer\n",
    "from nltk.corpus import words, stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.metrics.distance  import edit_distance, jaccard_distance\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text2 = \"loveli weathor today rigt? Hope it stays sanny all doy.\"\n",
    "correct_words = words.words()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*               Detecting wrong words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_mistakes(text):\n",
    "    tk = TweetTokenizer()\n",
    "    tokens = tk.tokenize(Text2)\n",
    "    tokens_list = []\n",
    "    Result_text = \"\"\n",
    "    for word in tokens:\n",
    "        if len(word) <= 1:\n",
    "            tokens_list.append(word)\n",
    "        elif (len(word) > 1 and word.lower() in correct_words) or ((len(word) > 1 and word.lower() in stop_words)):\n",
    "            tokens_list.append(word)\n",
    "        else:\n",
    "            tokens_list.append(colored(word, 'red'))\n",
    "    Result_text = \" \".join([str(word) for word in tokens_list])\n",
    "    ponc_with_space = [' , ',' ? ',' ! ']\n",
    "    ponc_with_nospace = [', ','? ','! ']\n",
    "    for i in range(len(ponc_with_space)):\n",
    "        Result_text = Result_text.replace(ponc_with_space[i],ponc_with_nospace[i])\n",
    "    print(Result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mloveli\u001b[0m \u001b[31mweathor\u001b[0m today \u001b[31mrigt\u001b[0m? Hope it stays \u001b[31msanny\u001b[0m all \u001b[31mdoy\u001b[0m .\n"
     ]
    }
   ],
   "source": [
    "detect_mistakes(Text2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*               Correcting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mloveli\u001b[0m \u001b[31mweathor\u001b[0m today \u001b[31mrigt\u001b[0m? Hope it stays \u001b[31msanny\u001b[0m all \u001b[31mdoy\u001b[0m .\n",
      "---------------------------------------------------------------------------\n",
      "In case, you don't get the wanted correction. Please type it. Else type no.\n",
      "---------------------------------------------------------------------------\n",
      "\u001b[31mloveli\u001b[0m  :  lovely  |  lovelily\n",
      "\u001b[31mweathor\u001b[0m  :  weather\n",
      "\u001b[31mrigt\u001b[0m  :  rift  |  rig |  right\n",
      "\u001b[31msanny\u001b[0m  :  sandy  |  sannyasi |  sunny\n",
      "\u001b[31mdoy\u001b[0m  :  day  |  do\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def correct_mistakes(text):\n",
    "    cor_words = {}\n",
    "    tk = TweetTokenizer()\n",
    "    tokens = tk.tokenize(text)\n",
    "    incorrect_words = []\n",
    "    for word in tokens:\n",
    "        if ((len(word) > 1 and word.lower() not in correct_words) and ((len(word) > 1 and word.lower() not in stop_words))):\n",
    "            incorrect_words.append(word)\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(\"In case, you don't get the wanted correction. Please type it. Else type no.\")\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    for word in incorrect_words:\n",
    "        \n",
    "        temp = [(edit_distance(word, w),w) for w in correct_words if w[0]==word[0]]\n",
    "        temp2 = [(jaccard_distance(set(ngrams(word, 2)),set(ngrams(w, 2))),w) for w in correct_words if w[0]==word[0]]\n",
    "\n",
    "        a = sorted(temp, key = lambda val:val[0])[0][1]\n",
    "        b = sorted(temp2, key = lambda val:val[0])[0][1]\n",
    "        \n",
    "        if a == b:\n",
    "            cor_words[word]=[a]\n",
    "            print(colored(word, 'red') , \" : \", a ,end = \"\")\n",
    "        else:\n",
    "            cor_words[word]=[a,b]\n",
    "            print(colored(word, 'red') , \" : \", a, \" | \", b, end = \"\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "        message = input(\"Add the wanted correction :\")\n",
    "\n",
    "        if message != \"no\":\n",
    "            print(\" | \",message)\n",
    "            cor_words[word].append(message)\n",
    "            \n",
    "        else:\n",
    "            print()\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    pickle.dump(cor_words, open('./cor_words.pkl', 'wb'))\n",
    "    pickle.dump(incorrect_words, open('./incorrect_words.pkl', 'wb'))\n",
    "\n",
    "detect_mistakes(Text2) \n",
    "correct_mistakes(Text2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*               select the wanted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the word loveli, please type the correct word among the following words : ['lovely', 'lovelily'].\n",
      "For the word weathor, please type the correct word among the following words : ['weather'].\n",
      "For the word rigt, please type the correct word among the following words : ['rift', 'rig', 'right'].\n",
      "For the word sanny, please type the correct word among the following words : ['sandy', 'sannyasi', 'sunny'].\n",
      "For the word doy, please type the correct word among the following words : ['day', 'do'].\n"
     ]
    }
   ],
   "source": [
    "def select_word():\n",
    "    cor_words = pickle.load(open('./cor_words.pkl','rb'))\n",
    "    chosen_words = []\n",
    "    for key, val in cor_words.items():\n",
    "        print(f\"For the word {key}, please type the correct word among the following words : {val}.\")\n",
    "        time.sleep(1)\n",
    "        message = input(\"You :\")\n",
    "        chosen_words.append(message)\n",
    "    pickle.dump(chosen_words, open('./chosen_words.pkl', 'wb'))\n",
    "\n",
    "select_word()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*               Update Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lovely weather today right? Hope it stays sunny all da.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def final_text(text):\n",
    "    incorrect_words = pickle.load(open('./incorrect_words.pkl','rb'))\n",
    "    chosen_words = pickle.load(open('./chosen_words.pkl','rb'))\n",
    "    for i in range(len(chosen_words)):\n",
    "        text = text.replace(incorrect_words[i],chosen_words[i])\n",
    "    return text\n",
    "\n",
    "final_text(Text2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
